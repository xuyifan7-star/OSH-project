# 大语言模型4个关键特征
1.理解能力。模型应该展示对自然语言文本的深刻理解，能够提取信息并执行各种语言相关的任务（如翻译）。
2.提示生成。模型应该有能力在提示时生成类似于人类习惯的文本。
3.上下文意识。模型应该通过考虑领域专业知识等因素来表现出上下文意识。
4.问题决策。模型应该擅长利用文本段落中下信息来解决问题和做出决策。
                        
参考资料：https://blog.csdn.net/u014250402/article/details/145163220

# 流行的LLM
可调性”列表明是否可以针对特定任务对这些模型进行微调。换句话说，可以采用大型的预训练语言模型，并在较小的特定领域数据集上调整其参数和训练，使其在特定任务上表现更好。

|大模型| GPT4| Cohere | BERT |T5|PaLM|Dolly
| :--------- | :---------:  |  :---------:  | :---------: | :---------: | :---------: | :---------: |
| 提供商 |OpenAI |  Cohere|Google|Google|Google|Databricks|
| 开源性|  N| N |Y|Y|Y|Y|
|可调性|N|Y|Y|Y|Y|Y|

# 用于数据安全和隐私的LLM

1.数据完整性：确保数据在其整个生命周期中未损坏，

-Wang Fang 的研究考察了使用 LLM 制定勒索软件网络安全策略，主要在理论上提出了实时分析、自动策略生成、预测分析和知识转移，但缺乏实证验证。（https://www.preprints.org/manuscript/202311.0676/v1）
-Liu 等人 探讨了 LLM 在创建网络安全策略方面的潜力，旨在通过数据泄露来缓解勒索软件攻击。他们将 GPT 生成的治理、风险和合规性 （GRC） 政策与来自成熟安全供应商和政府网络安全机构的政策进行了比较。他们建议公司应将 GPT 纳入其 GRC 政策制定中。（https://www.sciencedirect.com/science/article/pii/S0167404823003346）

2.数据机密性：保护敏感信息免遭未经授权的访问或披露的做法

